{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc3ef23c-9752-48a8-a014-19111edb0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "978f988c-fff4-4bfa-8d88-11b2d08e8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93cd84fa-f53e-4071-8fe2-f130b5a9c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "EMBEDDING_DIMENSIONALITY = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d07e38a-fc8e-4059-82f1-e190d9dafb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to delete a collection and make it again\n",
    "# client.delete_collection(collection_name=collection_name)\n",
    "\n",
    "# # Define the collection name\n",
    "collection_name = \"resume-rag\"\n",
    "\n",
    "# # Create the collection with specified vector parameters\n",
    "# client.create_collection(\n",
    "#     collection_name=collection_name,\n",
    "#     vectors_config=models.VectorParams(\n",
    "#         size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "#         distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# points = []\n",
    "# for i, doc in enumerate(document_raw):\n",
    "#     point = models.PointStruct(\n",
    "#         id=doc[\"id\"],  # or use id=i\n",
    "#         vector=models.Document(text=doc[\"text\"], model=model_handle),\n",
    "#         payload={\n",
    "#             \"text\": doc[\"text\"],\n",
    "#             \"section\": doc[\"metadata\"][\"section\"]\n",
    "#         }\n",
    "#     )\n",
    "#     points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3ab6e5-6858-465a-bea8-489b06892368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.upsert(\n",
    "#     collection_name=\"resume-rag\",\n",
    "#     points=points\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6b6ce85-9a75-42ad-ba6b-60bd69d56199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "465385f0-68be-4e2a-9908-5d1baecb839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai api\n",
    "API_KEY=os.environ.get(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(\n",
    "    api_key=API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27453adc-a714-4927-9dfc-1118052785cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groq api\n",
    "API_KEY=os.environ.get(\"GROQ_API_KEY\")\n",
    "groq_client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "216b4492-6447-4f77-8fc2-e41cd454309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "ollama_client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0889d388-2e05-433f-946b-6bf4fdecdc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(question, section=\"Work Experience\"):\n",
    "    #print('vector_search is used')\n",
    "\n",
    "    query_points = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=question,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        query_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"section\",\n",
    "                    match=models.MatchValue(value=section)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=5,\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    # Extract just the payloads (text + section)\n",
    "    results = []\n",
    "    for point in query_points.points:\n",
    "        results.append(point.payload)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "1ea0b37f-ee6e-4110-9fdb-3f652c39be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(question, sections=[\"Work Experience\"]):\n",
    "    # Support both string and list inputs\n",
    "    if isinstance(sections, str):\n",
    "        sections = [sections]\n",
    "\n",
    "    query_points = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=question,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        query_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"section\",\n",
    "                    match=models.MatchAny(any=sections)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=5,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    # Extract just the payloads (text + section)\n",
    "    results = [point.payload for point in query_points.points]\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ac94a8a-cf1b-4218-a9f2-ebbb8c92f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You are a resume assistant. Use the CONTEXT below to answer the QUESTION based only on the candidate's resume.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\n",
    "If the answer is not found in the context, reply with \"Not available in the resume.\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    # for doc in search_results:\n",
    "    #     context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    for doc in search_results:\n",
    "        text = doc.get(\"text\", \"\")\n",
    "        section = doc.get(\"section\", \"Unknown Section\")\n",
    "        context += f\"[{section}] {text}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "18a3d74a-31cc-46e4-b91d-da94ec394c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai api\n",
    "# def llm(prompt):\n",
    "#     response = openai_client.chat.completions.create(\n",
    "#         model='gpt-4o-mini',\n",
    "#         messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#     )\n",
    "    \n",
    "#     return response.choices[0].message.content\n",
    "\n",
    "# groq api\n",
    "def llm(prompt):\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model= \"llama-3.3-70b-versatile\", #\"llama-3.3-70b-versatile\",   #\"mistral-saba-24b\",  # or \"llama3-8b-8192\", \"gemma-7b-it\"\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# from ollama import Client\n",
    "\n",
    "# ollama_client = Client()\n",
    "\n",
    "# # ollama\n",
    "# def llm(prompt):\n",
    "#     response = ollama_client.chat(\n",
    "#         model='mistral',\n",
    "#         messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#     )\n",
    "#     return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a6230d43-4263-4786-ba58-ee5efebeef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    #search_results = vector_search(query, 'Work Experience')\n",
    "    search_results = vector_search(query, sections=[\"Work Experience\", \"Projects\", \"Skills\",\"Education\"])\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94d30ac4-7ae4-46c4-8143-9c2908db92c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key strengths of the candidate are:\n",
      "\n",
      "1. Machine Learning (ML) training and development\n",
      "2. Project efficiency improvement\n",
      "3. AI solution development for secure data processing\n",
      "4. ML pipeline optimization\n",
      "5. Revenue growth through machine learning techniques, particularly in predictive modeling and customer value estimation.\n",
      "\n",
      "These strengths are evident from the candidate's experience in training team members, developing ML solutions, improving pipeline efficiency, and generating significant revenue through machine learning applications.\n"
     ]
    }
   ],
   "source": [
    "print(rag('Summarise the key strengths'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faa3f87c-4d89-4db3-96b9-56066abe034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key strengths of the candidate include:\n",
      "\n",
      "1. Training and team management: Proven ability to train 10+ members across multiple clients.\n",
      "2. AI and Machine Learning solution development: Skilled in developing secure solutions for processing sensitive data.\n",
      "3. ML pipeline optimization: Able to improve efficiency by reducing grid search time and streamlining model logging.\n",
      "4. Machine learning techniques: Experienced in using techniques like Decision Trees, gradient-boosted decision trees, and performance metrics.\n",
      "5. Revenue generation: Successful in generating significant revenue through optimized call center interactions and predictive revenue forecasting.\n"
     ]
    }
   ],
   "source": [
    "print(rag('Summarise the key strengths'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f2d3ed2-97b3-4b52-96b7-27e7a60e612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the total years of work experience, we need to calculate the duration of employment at each position and then add them together.\n",
      "\n",
      "1. At Securiti, Karachi, Pakistan, the candidate started working in 11/2024 and is still working, so the duration is from 11/2024 to the current date. Since the current date is not specified, we can't calculate the exact duration, but it is less than a year.\n",
      "\n",
      "2. At Afiniti Software Solutions Ltd., Remote:\n",
      "   - The candidate worked as a Junior Data Scientist from 02/2020 to 05/2021, which is approximately 1 year and 3 months.\n",
      "   - Then, as a Data Scientist from 05/2021 to 05/2022, which is approximately 1 year.\n",
      "   - Finally, as a Data Scientist II from 05/2022 to 10/2024, which is approximately 2 years and 5 months.\n",
      "\n",
      "Adding these durations together: \n",
      "- Less than a year at Securiti\n",
      "- Approximately 1 year and 3 months + 1 year + 2 years and 5 months at Afiniti = 4 years and 8 months\n",
      "\n",
      "So, the total work experience is approximately more than 4 years and 8 months, but the exact duration of the current job is unknown.\n"
     ]
    }
   ],
   "source": [
    "print(rag('How many years of work experience are there?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2d3e1a5f-323e-4702-8482-cac70ac68381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key strengths of the candidate include:\n",
      "\n",
      "1. **Training and Leadership**: Experience in training over 10 team members on the ML pipeline, R programming, and client business, enhancing project efficiency.\n",
      "  \n",
      "2. **Process Improvement**: Proven ability to improve the efficiency of the ML pipeline by implementing strategies that significantly reduce processing time and standardize model logging.\n",
      "\n",
      "3. **End-to-End ML Development**: Skilled in managing the full ML lifecycle, from data collection and preparation to model training, evaluation, and production readiness, particularly for sensitive data.\n",
      "\n",
      "4. **Advanced ML Techniques**: Expertise in fine-tuning advanced models like LLaMA 3 for classification tasks, achieving high accuracy and adaptability in data processing.\n",
      "\n",
      "5. **Impactful Analytics**: Experience in optimizing business processes, such as call center interactions, through machine learning, resulting in significant revenue generation.\n"
     ]
    }
   ],
   "source": [
    "print(rag('Summarise the key strengths?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e1e16c68-1c6e-4589-a8da-e5520413f09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The candidate has built a CNN-based model to detect the header row location within semi-structured tabular files, achieving 96% accuracy and <250ms inference latency. Additionally, they have developed AI and Machine Learning solutions managing the full ML lifecycle, which includes model training and evaluation, and they have utilized gradient-boosted decision trees for predictive revenue forecasting and customer churn models.\n"
     ]
    }
   ],
   "source": [
    "print(rag('what work has the candidate done with deep learning?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee6c57a3-f2a9-4d9b-95be-7d59434f6e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_search is used\n",
      "The candidate's key strengths include:\n",
      "\n",
      "1. Strong training and leadership skills, evidenced by training over 10 members on ML pipelines and R programming, leading to increased project efficiency.\n",
      "2. Proven ability to enhance operational efficiency, demonstrated by reducing grid search time by 50% and streamlining model logging processes.\n",
      "3. Expertise in developing secure AI and Machine Learning solutions, managing the full ML lifecycle effectively.\n",
      "4. Proficient in fine-tuning machine learning models, with a notable achievement of ~92% accuracy in classifying personal data types.\n",
      "5. Successful application of machine learning techniques to optimize business processes, resulting in significant revenue generation for the company.\n"
     ]
    }
   ],
   "source": [
    "print(rag('Summarise the key strengths?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "355f2f84-ff19-4296-8b48-954d7a5c54ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_search is used\n",
      "The candidate is suited for roles such as:\n",
      "\n",
      "1. Machine Learning Engineer - due to their experience with gradient-boosted decision trees and fine-tuning models like LLaMA 3.\n",
      "2. Data Scientist - given their skills in predictive modeling, customer churn analysis, and working with structured data types.\n",
      "3. AI/ML Trainer - as they have trained team members on ML pipelines and R programming, enhancing project efficiency.\n",
      "4. Research Scientist - due to their experience with achieving high accuracy in classification tasks and model deployment. \n",
      "5. Technical Consultant - for their ability to integrate models into existing production systems and collaborate with engineering teams.\n"
     ]
    }
   ],
   "source": [
    "print(rag('what roles is the candidate suited for'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8481e9b-98f3-481a-b7e4-466e55c35cf2",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "5d5aecb5-e237-4584-94e9-6ba957431754",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/resume.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[291], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/resume.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     document_raw \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[1;32mC:\\projects\\ask_my_resume\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/resume.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/resume.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    document_raw = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a94608-fc4d-44be-a945-b04303c1d9ae",
   "metadata": {},
   "source": [
    "### Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "4a813156-53ec-45bd-b01b-e51971051d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an interviewer preparing for a behavioral or technical interview.\n",
    "Your goal is to write 5 clear and complete questions that would directly elicit the following resume entry as an answer.\n",
    "Only ask questions that can be directly answered using the provided entry. \n",
    "If the entry only includes company, job title, location, and dates, avoid asking technical or project-based questions.\n",
    "Avoid copying exact phrases from the resume — the questions should sound natural, but their answers should be well covered by the entry.\n",
    "\n",
    "section: {section}\n",
    "entry: {text}\n",
    "\n",
    "Provide the output in a JSON array only without using code blocks:\n",
    "[\"question1\", \"question2\", ..., \"question5\"]\n",
    "\"\"\".strip()\n",
    "\n",
    "# Formulate 5 questions a recruiter might ask during an interview based on the following resume entry.\n",
    "# Each question should probe deeper into the candidate's experience, technical choices, outcomes, or reasoning.\n",
    "\n",
    "# your current prompt is quite good, but it’s subtly prompting the model to review \n",
    "# the resume and formulate questions based on it, \n",
    "# which might lead to generic or curiosity-based questions \n",
    "# (e.g. \"Can you elaborate on your experience at XYZ?\") rather than \n",
    "# questions that would elicit that exact resume entry as the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "f59253f9-3292-4a04-b824-3d6f603ffd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an interviewer preparing for a behavioral or technical interview.\n",
      "Your goal is to write 5 clear and complete questions that would directly elicit the following resume entry as an answer.\n",
      "Only ask questions that can be directly answered using the provided entry. \n",
      "If the entry only includes company, job title, location, and dates, avoid asking technical or project-based questions.\n",
      "Avoid copying exact phrases from the resume — the questions should sound natural, but their answers should be well covered by the entry.\n",
      "\n",
      "section: Work Experience\n",
      "entry: Work Experience\n",
      "Securiti, Karachi, Pakistan\t11/2024 – Current\n",
      "Data Scientist\n",
      "\n",
      "Provide the output in a JSON array only without using code blocks:\n",
      "[\"question1\", \"question2\", ..., \"question5\"]\n"
     ]
    }
   ],
   "source": [
    "doc = document_raw[0]\n",
    "prompt = prompt_template.format(\n",
    "        section=doc[\"metadata\"][\"section\"],\n",
    "        text=doc[\"text\"]\n",
    "    )\n",
    "print(prompt)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "303e3ed0-7d7b-4ea6-bd21-2674685433ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    prompt = prompt_template.format(\n",
    "        section=doc[\"metadata\"][\"section\"],\n",
    "        text=doc[\"text\"]\n",
    "    )\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    json_response = response.choices[0].message.content\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c6f0237-baf4-4e5d-ae9e-bade5bbb6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "9e8c1afe-a30e-49ff-8d9e-835f825ca653",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3a164ffb-016b-4a1e-828c-d0f330bcd771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d8cdf354-30b6-4baf-9178-6cf98f5b1597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fe47c4fb-6883-43b6-bdd5-602a9a49fb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "350d38eb-1d4b-4b1f-8217-adab0dcdd9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'f6fce825-d0ec-474e-b869-948eaed8b877', 'text': 'Optimized call center interactions using machine learning techniques like Decision Trees and performance metrics to estimate customer lifetime value and agent impact, generating over $1 million in revenue per month for SKY UK.', 'metadata': {'section': 'Work Experience'}}\n",
      "[\n",
      "    \"Can you describe the techniques you utilized to enhance call center interactions?\",\n",
      "    \"What specific performance metrics did you focus on to assess customer lifetime value?\",\n",
      "    \"How did your work contribute to revenue generation at SKY UK?\",\n",
      "    \"Can you explain the role of machine learning in your approach to optimizing interactions?\",\n",
      "    \"What impact did the optimization have on the call center agents and their performance?\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(document_raw[7]) # 0, 6, \n",
    "\n",
    "print(generate_questions(document_raw[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d62008ad-3304-4644-a87f-c8cf570540ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d295500dcfc4e4daecf8f4efa394bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(document_raw): \n",
    "    doc_id = doc['id']\n",
    "    if doc_id in results:\n",
    "        continue\n",
    "\n",
    "    questions = generate_questions(doc)\n",
    "    #print(questions)\n",
    "    results[doc_id] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "b6118cbb-2840-44de-8e73-52f8fcd4970c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"What courses did you take that are related to machine learning?\", \"Can you list some of the subjects you studied that involved data structures?\", \"Which programming concepts did you learn in your education?\", \"What foundational courses did you take in statistics?\", \"How did your studies in object-oriented programming influence your understanding of software development?\"]'"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d5b6926b-d9cd-4d31-acfa-e4c51b959155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "751e3e90-974f-4b48-b35d-1b5b4088b74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4da2cf48-440f-4009-9948-1e0b63dd1e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Can you describe your experience with fine-tuning models like LLaMA 3?', 'What techniques did you use to improve the accuracy of classifying personal data types?', 'How did you ensure that the model could handle newly added personal data types during inference?', 'Could you explain the significance of achieving approximately 92% accuracy in your classification task?', 'What were the structured tables used for in your project, and how did they relate to your work?']\n"
     ]
    }
   ],
   "source": [
    "print(results['1eceaa59-8ffd-44fc-bc14-e5c5f49e1a1a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "39ffaecd-28a2-4b23-948a-9297d4b0b9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cae27263-b9ea-443e-91cf-6eacc852dbd2', 'text': 'Education\\nNational University of Sciences and Technology, Islamabad, Pakistan\\t2015 – 2019\\nB.E. Electrical Engineering', 'metadata': {'section': 'Education'}}\n"
     ]
    }
   ],
   "source": [
    "print(document_raw[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0b2bedc4-f0c6-4087-a850-faffe44c3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the results dictionary contains JSON strings instead of lists, we parse the string into a real list using json.loads\n",
    "# for doc_id in results:\n",
    "#     if isinstance(results[doc_id], str):\n",
    "#         results[doc_id] = json.loads(results[doc_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0b15a1d1-d2cd-4068-b24d-0b94b43bfd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save\n",
    "with open(\"questions_by_doc_id.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# # Load later\n",
    "# with open(\"questions_by_doc_id.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8684d87a-3919-40c5-ba6f-55dc2d154ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "67eecd1a-f498-4747-b28b-051fb22a20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id_to_section = {doc['id']:  doc[\"metadata\"][\"section\"] for doc in document_raw}\n",
    "\n",
    "# Flatten the results into a list of rows\n",
    "rows = []\n",
    "for doc_id, question_list in results.items():\n",
    "    section = doc_id_to_section.get(doc_id, \"Unknown\")\n",
    "\n",
    "     # Fix improperly stored stringified lists\n",
    "    if isinstance(question_list, str):\n",
    "        try:\n",
    "            question_list = json.loads(question_list)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to decode questions for doc_id {doc_id}\")\n",
    "            continue\n",
    "            \n",
    "    for question in question_list:\n",
    "        #print(question)\n",
    "        rows.append({\n",
    "            \"question\": question,\n",
    "            \"section\": section,\n",
    "            \"doc_id\": doc_id\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "25f34159-6ab7-493e-9719-f443fcee8416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "9ccf9da0-a95d-47d4-8d22-ad8f844ae2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c17a846f-a18a-43a6-9998-908c3c7b90b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/projects/ask_my_resume\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "51335109-859b-4a15-8b3f-ad3f4ecf449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/ground_truth_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "dd87a896-ecf9-4a0a-92ee-ccc0a329a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question,section,doc_id\n",
      "What is your current job title and where do you work?,Work Experience,ae0142cf-58e4-408a-b2c3-950b9864f8e9\n",
      "Can you tell me about the location of your current workplace?,Work Experience,ae0142cf-58e4-408a-b2c3-950b9864f8e9\n",
      "When did you start your current position?,Work Experience,ae0142cf-58e4-408a-b2c3-950b9864f8e9\n",
      "Are you currently working as a Data Scientist?,Work Experience,ae0142cf-58e4-408a-b2c3-950b9864f8e9\n",
      "What company are you employed with at the moment?,Work Experience,ae0142cf-58e4-408a-b2c3-950b9864f8e9\n",
      "Can you describe the type of solutions you developed related to AI and Machine Learning?,Work Experience,81b009b4-ca83-4f13-8549-684bceb6d767\n",
      "What was your role in managing the lifecycle of machine learning projects?,Work Experience,81b009b4-ca83-4f13-8549-684bceb6d767\n",
      "How did you ensure the security of sensitive data during your work?,Work Experience,81b009b4-ca83-4f13-8549-684bceb6d767\n",
      "What tasks did you perform in the data collection and preparation phases?,Work Experience,81b009b4-ca83-4f13-8549-684bceb6d767\n"
     ]
    }
   ],
   "source": [
    "!head data/ground_truth_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "313ba687-bafd-4d9f-9c29-0ec540c7eb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>section</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is your current job title and where do yo...</td>\n",
       "      <td>Work Experience</td>\n",
       "      <td>ae0142cf-58e4-408a-b2c3-950b9864f8e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can you tell me about the location of your cur...</td>\n",
       "      <td>Work Experience</td>\n",
       "      <td>ae0142cf-58e4-408a-b2c3-950b9864f8e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did you start your current position?</td>\n",
       "      <td>Work Experience</td>\n",
       "      <td>ae0142cf-58e4-408a-b2c3-950b9864f8e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are you currently working as a Data Scientist?</td>\n",
       "      <td>Work Experience</td>\n",
       "      <td>ae0142cf-58e4-408a-b2c3-950b9864f8e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What company are you employed with at the moment?</td>\n",
       "      <td>Work Experience</td>\n",
       "      <td>ae0142cf-58e4-408a-b2c3-950b9864f8e9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question          section  \\\n",
       "0  What is your current job title and where do yo...  Work Experience   \n",
       "1  Can you tell me about the location of your cur...  Work Experience   \n",
       "2          When did you start your current position?  Work Experience   \n",
       "3     Are you currently working as a Data Scientist?  Work Experience   \n",
       "4  What company are you employed with at the moment?  Work Experience   \n",
       "\n",
       "                                 doc_id  \n",
       "0  ae0142cf-58e4-408a-b2c3-950b9864f8e9  \n",
       "1  ae0142cf-58e4-408a-b2c3-950b9864f8e9  \n",
       "2  ae0142cf-58e4-408a-b2c3-950b9864f8e9  \n",
       "3  ae0142cf-58e4-408a-b2c3-950b9864f8e9  \n",
       "4  ae0142cf-58e4-408a-b2c3-950b9864f8e9  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_ground_truth = pd.read_csv('data/ground_truth_data.csv')\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "5c97120a-a9c7-4e84-8134-a02b6a8bcabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ground_truth = df_ground_truth[df_ground_truth.section.str.contains(\"Work Experience|Projects\")].to_dict(orient='records')\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "9be30cba-514f-4f0c-9055-603567061e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Integrated PyTorch models into a Java-based production pipeline for performance testing, collaborating closely with engineering teams to ensure seamless deployment.'"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating an index on document_raw to quickyl retrive the doc id answer from document_raw:\n",
    "# builds a dictionary (lookup index) where  key is id value from each document, and value is the full document entry\n",
    "doc_idx = {d[\"id\"]: d for d in document_raw}\n",
    "\n",
    "# # Now you can instantly access:\n",
    "# doc_text = doc_idx['3e1e2fd4-45c5-47dd-b4e6-f68835f53f6d'][\"text\"]\n",
    "# doc_section = doc_idx['3e1e2fd4-45c5-47dd-b4e6-f68835f53f6d'][\"metadata\"][\"section\"]\n",
    "# doc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "dfcb0643-9224-4a15-88a5-73b85a8bcf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a4c6dad8-4cd4-4417-afb3-0465ae24914c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you tell me about your current role and responsibilities at Securiti?'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f54b2681-2020-4897-8d53-9bfa9d83f4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"At Securiti, the candidate's current role is Data Scientist. Their specific responsibilities in this role are not available in the resume.\""
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(ground_truth[0]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "461a7758-2572-4872-9888-e3ab81f6333a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2122725b6d3f454eb582b7e3e57be235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, rec in enumerate(tqdm(ground_truth)):\n",
    "    if i in answers:\n",
    "        continue\n",
    "    #print(rec['question'])\n",
    "    answer_llm = rag(rec['question'])\n",
    "    doc_id = rec['doc_id']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_orig = original_doc['text']\n",
    "\n",
    "    answers[i] = {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'doc_id': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'section': rec['section'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10d13d-2e5f-4488-b347-2288094038e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(answers.values()).sample(5).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "effd2d00-e61a-421a-8376-30fc42d69d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "09c4cf47-ad4a-4388-b7be-3898b6cd029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_llama = pd.DataFrame(answers.values())#.sample(5).to_dict(orient='records')\n",
    "#os.makedirs('data', exist_ok=True)\n",
    "# df_results_llama.to_csv('data/results_llama-3.3-70b-versatile.csv', index=False)\n",
    "# df_results_llama.to_csv('data/llama-3.1-8b-instant.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19a12461-f036-4fff-995b-ae59a7417985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_llama = pd.read_csv('data/results_llama-3.3-70b-versatile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "8b1fde87-f1e9-4d55-86d3-b316297838e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_llama = df_results_llama.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1334a2b7-5f36-4088-bd2b-1e7bc67438aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\projects\\ask_my_resume\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9a1c7aee-f5f0-4dbb-8a0b-e964dfec4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_results_llama[['answer_orig','question','answer_llm']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e52dffd-5b68-4b22-9c2b-0ab7df7b3178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9a9f79f88140d1911e486e95c80c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\projects\\ask_my_resume\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Nida Khan\\.cache\\huggingface\\hub\\models--sentence-transformers--multi-qa-MiniLM-L6-cos-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2876b490f514f3bb78c90715236cf26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1388b07c5d4c738d4573e0af486c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4a92bea4d54acbb2d9a94c8b768fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4619750c585b468cbe0bd41e76ecbf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fdeb03d4c2546f19a20869aa6652441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932ff9777d92467fa7ed3381af4bca7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdafbd64a3c24c26882c81002cfb54e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45686421ae604416b81ace2bb324208d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2edb13063cf4761836bee07a934598e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89181d3e09ee449dacc75738179db8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# Trained on real QA pairs from diverse domains.\n",
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'  #'all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac1cf1f4-7bd4-4069-b137-d2c45e8afbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f588d54c10495ba65cd1b8b9d983ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\projects\\ask_my_resume\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Nida Khan\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651bed0ff05047179e58241d905c5816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b572a24a5744308faab3ef7bf0f18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79e054e81de4d95a80648f4b1fe9cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40071156e2634b5db9375370b38ec8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8e1064220648e0b601d9122fa7db94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6ac0ee8eb04d3d9502d15c78591f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b62610f24e3440987547f019210cf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e926fc531da43f38629ab33c3be6130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8a6d788ba34441bd2ea3f1800e834c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea2a8685fda41cf9128933d5d20c5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# Trained on real QA pairs from diverse domains.\n",
    "model_name_2 = 'all-MiniLM-L6-v2'\n",
    "model_2 = SentenceTransformer(model_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "34551e92-c078-483c-9e28-dbca86d641bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(record):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "    \n",
    "    # v_llm = model.encode(answer_llm)\n",
    "    # v_orig = model.encode(answer_orig)\n",
    "    v_llm = model_2.encode(answer_llm)\n",
    "    v_orig = model_2.encode(answer_orig)\n",
    "    \n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "6feecbfb-995e-4707-a0d7-25a309c7640a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7994bb648e794ba0802f7e6c3ef29c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarity = []\n",
    "\n",
    "for record in tqdm(results_llama):\n",
    "    sim = compute_similarity(record)\n",
    "    similarity.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "a76ae410-75d5-4404-bbd5-57100cf1db2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.510713</td>\n",
       "      <td>0.182568</td>\n",
       "      <td>0.090166</td>\n",
       "      <td>0.445921</td>\n",
       "      <td>0.543154</td>\n",
       "      <td>0.653294</td>\n",
       "      <td>0.685782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Projects</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.740273</td>\n",
       "      <td>0.143630</td>\n",
       "      <td>0.535940</td>\n",
       "      <td>0.633322</td>\n",
       "      <td>0.746957</td>\n",
       "      <td>0.850453</td>\n",
       "      <td>0.945555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skills</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.491292</td>\n",
       "      <td>0.149535</td>\n",
       "      <td>0.284191</td>\n",
       "      <td>0.418129</td>\n",
       "      <td>0.485872</td>\n",
       "      <td>0.620672</td>\n",
       "      <td>0.647595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work Experience</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.633545</td>\n",
       "      <td>0.267725</td>\n",
       "      <td>-0.061153</td>\n",
       "      <td>0.583262</td>\n",
       "      <td>0.727893</td>\n",
       "      <td>0.805798</td>\n",
       "      <td>0.926139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count      mean       std       min       25%       50%  \\\n",
       "section                                                                    \n",
       "Education         10.0  0.510713  0.182568  0.090166  0.445921  0.543154   \n",
       "Projects          10.0  0.740273  0.143630  0.535940  0.633322  0.746957   \n",
       "Skills             5.0  0.491292  0.149535  0.284191  0.418129  0.485872   \n",
       "Work Experience   70.0  0.633545  0.267725 -0.061153  0.583262  0.727893   \n",
       "\n",
       "                      75%       max  \n",
       "section                              \n",
       "Education        0.653294  0.685782  \n",
       "Projects         0.850453  0.945555  \n",
       "Skills           0.620672  0.647595  \n",
       "Work Experience  0.805798  0.926139  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_llama['cosine'] = similarity\n",
    "df_results_llama['cosine'].describe()\n",
    "df_results_llama.groupby('section')['cosine'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "051c28c7-6dfc-4deb-81b3-f22fc512fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_results_llama[['answer_orig','question','answer_llm','cosine']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f68a730-a71e-41ea-95ca-0bb8f65c245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\projects\\ask_my_resume\\.venv\\lib\\site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\projects\\ask_my_resume\\.venv\\lib\\site-packages (from seaborn) (2.3.1)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Using cached matplotlib-3.10.3-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading fonttools-4.58.5-cp310-cp310-win_amd64.whl.metadata (109 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\projects\\ask_my_resume\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\projects\\ask_my_resume\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\projects\\ask_my_resume\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\projects\\ask_my_resume\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\projects\\ask_my_resume\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\projects\\ask_my_resume\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached matplotlib-3.10.3-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.5-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 419.4 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.5/2.2 MB 419.4 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 0.8/2.2 MB 453.5 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 0.8/2.2 MB 453.5 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 0.8/2.2 MB 453.5 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 1.0/2.2 MB 479.2 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.0/2.2 MB 479.2 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 479.5 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 479.5 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 479.5 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.6/2.2 MB 490.5 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.6/2.2 MB 490.5 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.8/2.2 MB 498.4 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 498.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 512.9 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 512.9 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 512.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 465.4 kB/s eta 0:00:00\n",
      "Using cached kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ----- ---------------------------------- 1/7 [kiwisolver]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [cycler]\n",
      "   ---------------------- ----------------- 4/7 [contourpy]\n",
      "   ---------------------- ----------------- 4/7 [contourpy]\n",
      "   ---------------------- ----------------- 4/7 [contourpy]\n",
      "   ---------------------- ----------------- 4/7 [contourpy]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------------- 7/7 [seaborn]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.5 kiwisolver-1.4.8 matplotlib-3.10.3 pyparsing-3.2.3 seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0b0d55d8-66c5-459c-b055-bcacc50456c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_llama.to_csv('data/llama-3.3-70b-versatile_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a40867dd-7ed8-4dc1-85d8-b07750517b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nida Khan\\AppData\\Local\\Temp\\ipykernel_14644\\2336126269.py:3: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(df_results_llama['cosine'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='cosine', ylabel='Density'>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(df_results_llama['cosine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55608c0-8ceb-4c27-a3a8-58d574a5f930",
   "metadata": {},
   "source": [
    "### LLM as-a-Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "99bfb500-19f9-4470-92b0-ee0337c77444",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1_template = \"\"\"\n",
    "You are an expert evaluator for RAG-generated answers.\n",
    "\n",
    "Given:\n",
    "- A question\n",
    "- A generated answer\n",
    "- The original resume information\n",
    "\n",
    "Evaluate whether the answer is:\n",
    "1. **Correct** – factually answers the question well\n",
    "2. **Grounded** – based only on the resume info provided\n",
    "\n",
    "Then assign a score using this rubric:\n",
    "\n",
    "Score 2 = Answer is correct AND grounded  \n",
    "Score 1 = Answer is either correct OR grounded (but not both)  \n",
    "Score 0 = Answer is neither correct nor grounded\n",
    "\n",
    "Also provide a short explanation.\n",
    "\n",
    "Format your output as JSON without code blocks:\n",
    "{{\n",
    "  \"score\": 0 | 1 | 2,\n",
    "  \"explanation\": \"short justification\"\n",
    "}}\n",
    "\n",
    "---\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER:\n",
    "{answer_llm}\n",
    "\n",
    "REFERENCE (Resume Entry):\n",
    "{answer_orig}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3547c48c-c918-4f4d-810a-67eb6b33e247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you tell me about your current role and responsibilities at Securiti?'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_llama.loc[0, 'question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "88f2ce36-72ec-4f50-9449-079f3c1350ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = prompt1_template.format(\n",
    "        question=df_results_llama.loc[0, \"question\"],\n",
    "        answer_llm=df_results_llama.loc[0, \"answer_llm\"],\n",
    "        answer_orig=df_results_llama.loc[0, \"answer_orig\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "1858a242-5b71-453a-a5e9-f23eeeec0049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  'score': 1,\n",
      "  'explanation': 'The answer correctly identifies the role as Data Scientist at Securiti but includes an incorrect start date of November 2024, which is not grounded in the present context since that date is in the future.'  \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f6015247-256e-4d01-8a9f-93f0046fe31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "                model='gpt-4o-mini',\n",
    "                messages=[{\"role\": \"user\", \"content\": pp}]\n",
    "            )\n",
    "content = response.choices[0].message.content\n",
    "cc = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a9d9cf71-1da0-4666-b074-5673f5e7f55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1,\n",
       " 'explanation': 'The answer is correct in stating the role and starting date but is not grounded since the date is in the future (November 2024) and thus not possible at the time of evaluation.'}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c5b7f-0c2a-47df-af2d-16bd2cde94a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "b82fd436-df49-42ba-be16-fef99b79ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def evaluate_row(row):\n",
    "    prompt = prompt1_template.format(\n",
    "        question=row[\"question\"],\n",
    "        answer_llm=row[\"answer_llm\"],\n",
    "        answer_orig=row[\"answer_orig\"]\n",
    "    )\n",
    "    \n",
    "    # Call to Groq API or your LLM\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "                model='gpt-4o-mini',\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "        content = response.choices[0].message.content\n",
    "        result = json.loads(content)\n",
    "\n",
    "        return pd.Series({\n",
    "            \"score_llm_eval\": result.get(\"score\"),\n",
    "            \"judge_explanation\": result.get(\"explanation\")\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        return pd.Series({\n",
    "            \"score_llm_eval\": None,\n",
    "            \"judge_explanation\": f\"Error: {str(e)}\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "06ab8c98-65ee-4d5f-af67-22baae86a407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b291efe9a3442d96da11f00f7095e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df_results_llama[[\"score_llm_eval\", \"judge_explanation\"]] = df_results_llama.progress_apply(evaluate_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "63be77d9-ff83-4059-8299-497b3e19669c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_llm_eval\n",
       "2    72\n",
       "1    17\n",
       "0     6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_llama['score_llm_eval'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "155044ab-3688-4a0d-bf86-c275ba646338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer_orig': 'Integrated PyTorch models into a Java-based production pipeline for performance testing, collaborating closely with engineering teams to ensure seamless deployment.',\n",
       "  'question': 'What challenges did you face when integrating different technologies like PyTorch and Java?',\n",
       "  'answer_llm': 'Not available in the resume.',\n",
       "  'cosine': -0.045038048177957535,\n",
       "  'judge_explanation': 'The answer is incorrect as it does not address the question about challenges faced during integration. It is also not grounded, as it does not use or reference the information provided in the resume.'},\n",
       " {'answer_orig': 'Fine-tuned LLaMA 3 using PEFT (LoRA) to classify personal data (PD) types of columns in structured tables, achieving ~92% accuracy across 15+ PD types, and enabling classification of newly added PD types during inference.',\n",
       "  'question': 'What was the significance of reaching approximately 92% accuracy in your project?',\n",
       "  'answer_llm': 'Not available in the resume.',\n",
       "  'cosine': 0.13769537210464478,\n",
       "  'judge_explanation': 'The answer does not provide any information related to the significance of the accuracy achieved in the project, nor does it reference any details from the resume.'},\n",
       " {'answer_orig': 'Conducted extensive grid search experiments comprising of 2000+ models to find optimal hyper parameters.',\n",
       "  'question': 'What were some challenges you faced while conducting your grid search experiments?',\n",
       "  'answer_llm': 'Not available in the resume.',\n",
       "  'cosine': -0.04457610845565796,\n",
       "  'judge_explanation': 'The answer does not address any challenges faced during the experiments and is not supported by the resume information, which only describes the grid search without mentioning any challenges.'},\n",
       " {'answer_orig': 'Improved the efficiency of the ML pipeline by implementing strategies to reduce grid search time by 50%, and adding features to streamline and standardize the process of model logging.',\n",
       "  'question': 'Can you discuss a challenge you faced while working on the ML pipeline and how you addressed it?',\n",
       "  'answer_llm': 'Not available in the resume.',\n",
       "  'cosine': -0.010332215577363968,\n",
       "  'judge_explanation': 'The answer does not provide any information or details related to the challenge faced while working on the ML pipeline, nor is it derived from the resume information, which primarily discusses an improvement made.'},\n",
       " {'answer_orig': 'Designed interactive dashboards using R and Python, resulting in streamlined tracking and visualization of KPIs.',\n",
       "  'question': 'Can you explain any challenges you faced while designing interactive dashboards?',\n",
       "  'answer_llm': 'Not available in the resume.',\n",
       "  'cosine': 0.008716483600437641,\n",
       "  'judge_explanation': 'The answer does not address the question and lacks any reference to challenges faced, which are not mentioned in the resume. Therefore, it is neither correct nor grounded.'},\n",
       " {'answer_orig': 'Courses: Machine Learning, Probability & Statistics, Data Structures & Algorithms, Object-Oriented Programming',\n",
       "  'question': 'How did your studies in object-oriented programming influence your understanding of software development?',\n",
       "  'answer_llm': 'Not available in the resume.',\n",
       "  'cosine': 0.09016644209623337,\n",
       "  'judge_explanation': 'The answer does not address the question and provides no relevant information from the resume. Therefore, it is neither correct nor grounded.'}]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_llama[df_results_llama.score_llm_eval==0][['answer_orig','question','answer_llm','cosine','judge_explanation']].to_dict(orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ask_my_resume)",
   "language": "python",
   "name": "ask_my_resume"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
